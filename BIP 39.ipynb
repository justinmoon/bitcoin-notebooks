{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, binascii, hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab English Wordlist From BIP Git Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_wordlist_url = \"https://raw.githubusercontent.com/bitcoin/bips/master/bip-0039/english.txt\"\n",
    "response = requests.get(english_wordlist_url)\n",
    "wordlist = response.text.splitlines()\n",
    "assert len(wordlist) == 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Mnemonic From Random Bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entropy(n):\n",
    "    return os.urandom(n)\n",
    "\n",
    "def mnemonic_from_entropy(entropy_bytes):\n",
    "    entropy_bits_length = len(entropy_bytes) * 8\n",
    "    checksum_bits_length = entropy_bits_length // 32\n",
    "    sequence_length = (entropy_bits_length + checksum_bits_length) // 11\n",
    "    \n",
    "    # Prepare entropy bits\n",
    "    entropy_bits = bin(int(binascii.hexlify(entropy), 16))[2:]\n",
    "    padded_entropy_bits = entropy_bits.zfill(entropy_bits_length)\n",
    "    \n",
    "    # Prepare checksum\n",
    "    entropy_hash = hashlib.sha256(entropy).hexdigest()\n",
    "    entropy_hash_int = int(entropy_hash, 16)\n",
    "    entropy_hash_bits = bin(int(entropy_hash, 16))[2:]\n",
    "    padded_entropy_hash_bits = entropy_hash_bits.zfill(256)\n",
    "    checksum = padded_entropy_hash_bits[:checksum_bits_length]\n",
    "    \n",
    "    # Take 11 bit slices of padded_entropy_bits + checksum\n",
    "    # Interpret as int, pluck work from wordlist at this index\n",
    "    sequence = padded_entropy_bits + checksum\n",
    "    result = []\n",
    "    for i in range(sequence_length):\n",
    "        index = int(sequence[i * 11:(i + 1) * 11], 2)\n",
    "        result.append(wordlist[index])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'F\\xfa\\x02\\xdb\\xe6\\x03\\xd6\\x9e\\n\\xefW\\x7f+\\x95\\xc0\\xa5\\xd1b\\xca\\xe9\\xf4\\xd1\\x85\\x106\\xb2v\\xaba\\xe7\\x11\\xee'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy = generate_entropy(32)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['belt',\n",
       " 'shell',\n",
       " 'fossil',\n",
       " 'bullet',\n",
       " 'impose',\n",
       " 'monkey',\n",
       " 'common',\n",
       " 'lunch',\n",
       " 'tone',\n",
       " 'season',\n",
       " 'boil',\n",
       " 'share',\n",
       " 'shop',\n",
       " 'angle',\n",
       " 'humor',\n",
       " 'adapt',\n",
       " 'path',\n",
       " 'plug',\n",
       " 'movie',\n",
       " 'metal',\n",
       " 'trend',\n",
       " 'bracket',\n",
       " 'dilemma',\n",
       " 'depth']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnemonic_from_entropy(entropy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
